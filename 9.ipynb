{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11a29db",
   "metadata": {},
   "source": [
    "In the AdaBoost algorithm, the weights of misclassified samples are updated to emphasize the importance of these samples in subsequent iterations. The process of updating the weights involves increasing the weights of misclassified samples and decreasing the weights of correctly classified samples. This adjustment ensures that the subsequent weak learners focus more on the difficult-to-classify instances.\n",
    "\n",
    "Here's how AdaBoost updates the weights of misclassified samples:\n",
    "\n",
    "Initialization:\n",
    "\n",
    "Initially, all samples in the training dataset are assigned equal weights \n",
    "�\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "w \n",
    "i\n",
    "​\n",
    " = \n",
    "N\n",
    "1\n",
    "​\n",
    " , where \n",
    "�\n",
    "N is the total number of samples.\n",
    "Training Weak Learner:\n",
    "\n",
    "AdaBoost trains a weak learner (e.g., decision stump) on the weighted training dataset.\n",
    "The weak learner aims to minimize the weighted classification error, where the weights are assigned to each sample.\n",
    "Calculation of Weighted Error:\n",
    "\n",
    "After training the weak learner, its performance is evaluated by calculating the weighted error. The weighted error is the sum of the weights of misclassified samples.\n",
    "Formally, the weighted error \n",
    "�\n",
    "�\n",
    "ϵ \n",
    "t\n",
    "​\n",
    "  of the \n",
    "�\n",
    "t-th weak learner is calculated as:\n",
    "�\n",
    "�\n",
    "=\n",
    "∑\n",
    "�\n",
    "=\n",
    "1\n",
    "�\n",
    "�\n",
    "�\n",
    "⋅\n",
    "1\n",
    "(\n",
    "�\n",
    "�\n",
    "≠\n",
    "ℎ\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    ")\n",
    "ϵ \n",
    "t\n",
    "​\n",
    " =∑ \n",
    "i=1\n",
    "N\n",
    "​\n",
    " w \n",
    "i\n",
    "​\n",
    " ⋅1(y \n",
    "i\n",
    "​\n",
    " \n",
    "\n",
    "=h \n",
    "t\n",
    "​\n",
    " (x \n",
    "i\n",
    "​\n",
    " ))\n",
    "where \n",
    "�\n",
    "�\n",
    "w \n",
    "i\n",
    "​\n",
    "  is the weight of the \n",
    "�\n",
    "i-th sample, \n",
    "�\n",
    "�\n",
    "y \n",
    "i\n",
    "​\n",
    "  is the true label of the \n",
    "�\n",
    "i-th sample, \n",
    "ℎ\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "h \n",
    "t\n",
    "​\n",
    " (x \n",
    "i\n",
    "​\n",
    " ) is the prediction of the \n",
    "�\n",
    "t-th weak learner on the \n",
    "�\n",
    "i-th sample, and \n",
    "1\n",
    "(\n",
    "⋅\n",
    ")\n",
    "1(⋅) is the indicator function.\n",
    "Calculation of Learner Weight:\n",
    "\n",
    "The weight \n",
    "�\n",
    "�\n",
    "α \n",
    "t\n",
    "​\n",
    "  of the \n",
    "�\n",
    "t-th weak learner is calculated based on its performance. Higher accuracy leads to a higher weight.\n",
    "The weight \n",
    "�\n",
    "�\n",
    "α \n",
    "t\n",
    "​\n",
    "  is calculated as:\n",
    "�\n",
    "�\n",
    "=\n",
    "1\n",
    "2\n",
    "ln\n",
    "⁡\n",
    "(\n",
    "1\n",
    "−\n",
    "�\n",
    "�\n",
    "�\n",
    "�\n",
    ")\n",
    "α \n",
    "t\n",
    "​\n",
    " = \n",
    "2\n",
    "1\n",
    "​\n",
    " ln( \n",
    "ϵ \n",
    "t\n",
    "​\n",
    " \n",
    "1−ϵ \n",
    "t\n",
    "​\n",
    " \n",
    "​\n",
    " )\n",
    "where \n",
    "�\n",
    "�\n",
    "ϵ \n",
    "t\n",
    "​\n",
    "  is the weighted error of the weak learner.\n",
    "Updating Sample Weights:\n",
    "\n",
    "The sample weights are updated based on the performance of the weak learner.\n",
    "For misclassified samples, their weights are increased, while for correctly classified samples, their weights are decreased.\n",
    "The updated weights are calculated as:\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    "+\n",
    "1\n",
    ")\n",
    "=\n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "⋅\n",
    "exp\n",
    "⁡\n",
    "(\n",
    "−\n",
    "�\n",
    "�\n",
    "⋅\n",
    "�\n",
    "�\n",
    "⋅\n",
    "ℎ\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    ")\n",
    "w \n",
    "i\n",
    "(t+1)\n",
    "​\n",
    " =w \n",
    "i\n",
    "(t)\n",
    "​\n",
    " ⋅exp(−α \n",
    "t\n",
    "​\n",
    " ⋅y \n",
    "i\n",
    "​\n",
    " ⋅h \n",
    "t\n",
    "​\n",
    " (x \n",
    "i\n",
    "​\n",
    " ))\n",
    "where \n",
    "�\n",
    "�\n",
    "(\n",
    "�\n",
    ")\n",
    "w \n",
    "i\n",
    "(t)\n",
    "​\n",
    "  is the weight of the \n",
    "�\n",
    "i-th sample after the \n",
    "�\n",
    "t-th iteration, \n",
    "�\n",
    "�\n",
    "α \n",
    "t\n",
    "​\n",
    "  is the weight of the \n",
    "�\n",
    "t-th weak learner, \n",
    "�\n",
    "�\n",
    "y \n",
    "i\n",
    "​\n",
    "  is the true label of the \n",
    "�\n",
    "i-th sample, \n",
    "ℎ\n",
    "�\n",
    "(\n",
    "�\n",
    "�\n",
    ")\n",
    "h \n",
    "t\n",
    "​\n",
    " (x \n",
    "i\n",
    "​\n",
    " ) is the prediction of the \n",
    "�\n",
    "t-th weak learner on the \n",
    "�\n",
    "i-th sample.\n",
    "Normalization of Weights:\n",
    "\n",
    "After updating the weights, they are normalized to ensure that they sum up to 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
